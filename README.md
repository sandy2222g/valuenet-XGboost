# Boston House Price Prediction API & Web App

A full-stack, Dockerized machine learning application that predicts house prices using a trained XGBoost model, served via a FastAPI backend with a Streamlit frontend.

<!-- ![Screenshot of the Streamlit App](<URL_TO_YOUR_SCREENSHOT_HERE>) -->
*(Note: Add a screenshot of your running Streamlit app here for a great visual first impression!)*

---

## üåü Key Features

*   **Interactive Web UI**: A user-friendly frontend built with Streamlit to input house features and get predictions.
*   **Robust API Backend**: A high-performance FastAPI backend that serves the machine learning model.
*   **Automatic API Documentation**: Interactive API documentation (via Swagger UI) is automatically generated by FastAPI.
*   **Fully Containerized**: The entire application stack is containerized with Docker and orchestrated with Docker Compose for easy setup and portability.
*   **Clean, Modular Code**: The project is structured with a clear separation of concerns for the frontend, backend, and machine learning model code.

## üõ†Ô∏è Tech Stack

*   **Backend**: Python, FastAPI, Uvicorn
*   **Frontend**: Streamlit
*   **Machine Learning**: Scikit-learn, XGBoost, Pandas
*   **Containerization**: Docker, Docker Compose

## üèóÔ∏è Architecture

This project follows a simple three-tier architecture:

1.  **Frontend (Streamlit)**: The user interacts with the web interface, providing input features for a house. It sends these features to the backend API.
2.  **Backend (FastAPI)**: The API receives the request, validates the input data, passes it to the machine learning model, and returns the model's prediction as a JSON response.
3.  **ML Model (XGBoost)**: A pre-trained XGBoost model (`xgb_model.joblib`) that performs the actual price prediction based on the input features.

## üöÄ Getting Started

### Prerequisites

*   **Docker** and **Docker Compose** must be installed on your machine.
*   A Python environment to run the initial training script.

### 1. Train the Model (One-Time Setup)

Before you can run the application, you need to generate the trained model file.

**a. Install local dependencies:**
*(It's highly recommended to do this in a Python virtual environment)*
```bash
pip install -r requirements.txt
```

**b. Run the training script:**
This command will create the `models/xgb_model.joblib` file.
```bash
python main.py --action train
```

### 2. Run the Application with Docker

Once the model file (`xgb_model.joblib`) exists, you can build and run the entire application stack with a single command from the project root directory:

```bash
docker-compose up --build
```

This command will build the Docker images, start the containers, and connect them.

### 3. Access the Applications

Once the containers are running, you can access the services:

*   **Frontend Web App**:
    *   Open your browser and go to: **`http://localhost:8501`**

*   **Backend API Docs**:
    *   The API is served at `http://localhost:8000`.
    *   View the interactive documentation at: **`http://localhost:8000/docs`**

### 4. Stopping the Application

To stop and remove the containers and network, press `Ctrl+C` in the terminal where Docker Compose is running, and then execute:

```bash
docker-compose down
```

## üí° Future Improvements

*   **Add Unit & Integration Tests**: Implement tests for the API and model logic.
*   **CI/CD Pipeline**: Set up a GitHub Actions workflow to automatically build and test the application.
*   **Cloud Deployment**: Deploy the application to a cloud service like AWS, GCP, or Heroku.
*   **Hyperparameter Tuning**: Add a script to perform hyperparameter tuning to potentially improve model accuracy.